{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv \n",
    "import re\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"homework3.txt\", \"w\")\n",
    "\n",
    "for i in range(201,300):\n",
    "    page = requests.get(\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page=\" + str(i))\n",
    "    soup = BeautifulSoup(page.content, features=\"lxml\")\n",
    "    links = soup.find_all('a', itemprop='url', class_='bookTitle')\n",
    "    for link in links:\n",
    "        fullLink = link.get('href')\n",
    "        f.write('https://www.goodreads.com' + fullLink + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/Storage file PC/Documenti/Università/Data Science/Anno 1/Semestre 1/Algorthmic Methods of Data Mining/Homeworks/HW3/storage/' # MODIFY!!!!!!!!!!!!!!\n",
    "\n",
    "d = 7278\n",
    "\n",
    "for i in range(27079, 29701):\n",
    "    \n",
    "    d += 1\n",
    "    \n",
    "    folderName = \"folder-\" + str(i) + \"/\"\n",
    "    fileName = \"article_\" + str(i) + \".html\"\n",
    "    \n",
    "    f = open(\"homework3.txt\", \"r\")\n",
    "    url = f.readlines()[d]\n",
    "    \n",
    "    Path(path + folderName).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    page = requests.get(url)\n",
    "    code = str(page.text)\n",
    "\n",
    "    with open(path + folderName + fileName, \"w\", encoding=\"utf-8\") as z:\n",
    "        z.write(code)\n",
    "\n",
    "    z.close()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"homework3.txt\", \"r\") #aprire il proprio file .txt degli URLs\n",
    "l=f1.readlines()\n",
    "data = ['bookTitle', 'bookSeries', 'bookAuthors', 'ratingValue',\"ratingCount\",\"reviewCount\",\"Plot\",\"NumberofPages\",\"Publishing Date\",\"Characters\",\"Setting\",\"Url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cambiare path con il proprio!!!\n",
    "\n",
    "for i in range(19801, 19803): #al posto di 2 va messo len(l)\n",
    "    with open('D:/Storage file PC/Documenti/Università/Data Science/Anno 1/Semestre 1/Algorthmic Methods of Data Mining/Homeworks/HW3/storage/folder-'+str(i)+\"/article_\"+str(i)+\".html\", 'rb') as html:  #cambiare path!!!\n",
    "        soup = BeautifulSoup(html,\"html.parser\")\n",
    "    lista=[]\n",
    "    #title\n",
    "    try:\n",
    "        lista.append(soup.find('h1').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #bookseries\n",
    "    try:\n",
    "        lista.append(soup.find('h2',id='bookSeries').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #author name\n",
    "    try:\n",
    "        lista.append(soup.find('a',class_='authorName').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #rating value\n",
    "    try:\n",
    "        lista.append(soup.find('span',itemprop='ratingValue').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #ratingCount\n",
    "    try:\n",
    "        lista.append(soup.find_all('a',class_='gr-hyperlink',href='#other_reviews')[0].text.strip().replace('\\r', '').replace('\\n', ''))\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #reviewCount\n",
    "    try:\n",
    "        lista.append(soup.find_all('a',class_='gr-hyperlink',href='#other_reviews')[1].text.strip().replace('\\r', '').replace('\\n', ''))\n",
    "    except:\n",
    "        lista.append('')\n",
    "    \n",
    "    #plot\n",
    "    try:\n",
    "        plott=soup.find('div',id='description').contents[1].text.strip()+soup.find('div',id='description').contents[3].text.strip()\n",
    "        if detect(plott)=='en':\n",
    "            lista.append(plott)\n",
    "        else:\n",
    "            lista.append('')\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #number of pages\n",
    "    try:\n",
    "        lista.append(soup.find('span', itemprop='numberOfPages').text.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #Publishing Date\n",
    "    try:\n",
    "        a=soup.find_all('div', class_='row')[1].text\n",
    "        match_obj = re.split('Published', re.split('by', a)[0])[1]\n",
    "        lista.append(match_obj.strip())\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #characters\n",
    "    try:\n",
    "        lista.append(soup.find_all('div',class_=\"infoBoxRowItem\")[4].text.strip().replace('...more','').replace('...less',''))\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #setting\n",
    "    try:\n",
    "        lista.append(soup.find_all('div',class_=\"infoBoxRowItem\")[5].text.strip().replace('\\n','').replace('\\r',''))\n",
    "    except:\n",
    "        lista.append('')\n",
    "        \n",
    "    #URL\n",
    "    lista.append(soup.find('link')['href'].strip())\n",
    "    \n",
    "    path=\"D:/Storage file PC/Documenti/Università/Data Science/Anno 1/Semestre 1/Algorthmic Methods of Data Mining/Homeworks/HW3/storage/folder-\"+str(i)+'/article_'+str(i)+'.tsv'        #cambiare path!!!!!!\n",
    "    with open(path, 'w', newline='') as f_output:\n",
    "        tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "        tsv_output.writerow(data)\n",
    "        tsv_output.writerow(lista)\n",
    "        f_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
